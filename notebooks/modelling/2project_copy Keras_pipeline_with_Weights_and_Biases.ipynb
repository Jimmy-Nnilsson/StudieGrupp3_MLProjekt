{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["TF:  2.7.0\n"]}],"source":["import os\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import tensorflow as tf\n","print(\"TF: \", tf.__version__)\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from keras import Model\n","\n","from pathlib import Path\n","from keras.preprocessing.image import load_img, img_to_array, image_dataset_from_directory\n","from tensorflow.keras.applications import vgg16, vgg19\n","\n","import wandb\n","from wandb.keras import WandbCallback"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def seed_everything():\n","    os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n","    np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n","    tf.random.set_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n","\n","seed_everything()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","# Get base project directory\n","project_path = Path(os.getcwd()).parent.parent\n","datapath = (project_path /'data/processed/')\n","\n","CLASSES = {0 : 'yes', 1 : 'no'}\n","# Loops through pathlist and reads and resizes images\n","def read_image(pathlist : list, size : int)-> list:\n","    data = []\n","    for path in pathlist:\n","        image=load_img(path, color_mode='rgb', target_size=(size, size))\n","        image=img_to_array(image)\n","        # image=image/255.0\n","        data.append(image)\n","    return data\n","\n","# Makes input and label data from folder locations.\n","# Loops through location \"subfolder/CLASSES\"\n","def get_sets(subfolder : str, CLASSES : dict, size : int) -> tuple[list, list]:\n","    folder_paths = []\n","    folder_labels = []\n","    labels = []\n","    for k,v in CLASSES.items():\n","        # input datapath generation\n","        folder_paths += list((datapath / f\"2_split_{v}/{subfolder}\").rglob(\"*\"))\n","    # Label data generation\n","    folder_labels = [0 if x.stem.split('_')[1] == 'yes' else 1 for x in folder_paths]\n","    # Extract images from datapaths\n","    img_list = read_image(folder_paths, size)\n","\n","    return img_list, folder_labels\n","\n","def get_training_set(CLASSES : dict, size : int) -> tuple[list, list]:\n","    folder_paths = []\n","    folder_labels = []\n","    labels = []\n","    for k,v in CLASSES.items():\n","        # input datapath generation\n","        folder_paths += list((datapath / f\"3_aug_{v}_train/\").rglob(\"*\"))\n","        # print(folder_paths)\n","    # Label data generation\n","    folder_labels = [0 if x.stem.split('_')[1] == 'yes' else 1 for x in folder_paths]\n","    # Extract images from datapaths\n","    img_list = read_image(folder_paths, size)\n","\n","    return img_list, folder_labels"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Dataset inspect\n","# Read images to variables\n","size = 224\n","# X_train, y_train = get_training_set(CLASSES, size)\n","X_train, y_train = get_sets('train', CLASSES, size)\n","X_val, y_val = get_sets('val', CLASSES, size)\n","X_test, y_test = get_sets('test', CLASSES, size)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"BACMLdC0I-w3"},"outputs":[],"source":["#@title\n","@tf.function\n","def preprocess(image: tf.Tensor, label: tf.Tensor):\n","    \"\"\"\n","    Preprocess the image tensors and parse the labels\n","    \"\"\"\n","    # Preprocess images\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    \n","    # Parse label\n","    label = tf.cast(label, tf.float32)\n","    \n","    return image, label\n","\n","\n","def prepare_dataloader(images: np.ndarray,\n","                       labels: np.ndarray,\n","                       loader_type: str='train',\n","                       batch_size: int=128):\n","    \"\"\"\n","    Utility function to prepare dataloader.\n","    \"\"\"\n","    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n","\n","    if loader_type=='train':\n","        dataset = dataset.shuffle(1024)\n","\n","    dataloader = (\n","        dataset\n","        .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","        .batch(batch_size)\n","        .prefetch(tf.data.AUTOTUNE)\n","    )\n","\n","    return dataloader"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"KHhaOEzCI-w0"},"outputs":[],"source":["configs = dict(\n","    image_width = X_train[0].shape[0],\n","    image_height = X_train[0].shape[1],\n","    image_channels = X_train[0].shape[2],\n","    batch_size = 32,\n","    class_names = CLASSES,\n","    model_name = '', # set after model is defined\n","    pretrain_weights = 'imagenet',\n","    epochs = 5,\n","    init_learning_rate = 0.001,\n","    lr_decay_rate = 0.1,\n","    optimizer = 'adam',\n","    loss_fn = 'binary_crossentropy',\n","    metrics = ['accuracy'],\n","    earlystopping_patience = 5,\n","    architecture = \"\",# To be defined f\"{base_model._name.upper()} global_average_pooling2d\",\n","    dataset = \"Brain_MRI_Images_for_Brain_Tumor_Detection\"\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dVtM4jajI-w4"},"outputs":[],"source":["trainloader = prepare_dataloader(X_train, y_train, 'train', configs.get('batch_size', 64))\n","validloader = prepare_dataloader(X_val, y_val, 'valid', configs.get('batch_size', 64))\n","testloader = prepare_dataloader(X_test, y_test, 'test', configs.get('batch_size', 64))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"uAnYG27BI-w2"},"outputs":[],"source":["# train_images, train_labels, valid_images, valid_labels, test_images, test_labels = download_and_prepare_dataset(info)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"pCaZpItDI-w2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of train images : 5 to be logged\n"]}],"source":["# For demonstration purposes\n","log_full = False #@param {type:\"boolean\"}\n","\n","if log_full:\n","    log_train_samples = len(X_train)\n","else:\n","    log_train_samples = 5 \n","\n","print(f'Number of train images : {log_train_samples} to be logged')"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["ds = wandb.Artifact(configs[\"dataset\"], \"dataset\")\n","\n","# Initialize an empty table\n","train_table = wandb.Table(columns=[], data=[])\n","# Add training data\n","train_table.add_column('image', X_train[:log_train_samples])\n","# Add training label_id\n","train_table.add_column('label_id', y_train[:log_train_samples])\n","# Add training class names\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'0'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4408/1915107860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_table.add_computed_columns(lambda ndx, row:{\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"images\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"class_names\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     })\n","\u001b[1;32m~\\anaconda3\\envs\\g3\\lib\\site-packages\\wandb\\data_types.py\u001b[0m in \u001b[0;36madd_computed_columns\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mndx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mnew_row_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_row_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_row_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4408/1915107860.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(ndx, row)\u001b[0m\n\u001b[0;32m      1\u001b[0m train_table.add_computed_columns(lambda ndx, row:{\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"images\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;34m\"class_names\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     })\n","\u001b[1;31mKeyError\u001b[0m: '0'"]}],"source":["\n","train_table.add_computed_columns(lambda ndx, row:{\n","    \"images\": wandb.Image(row[\"image\"]),\n","    \"class_names\": configs['class_names'][str(row[\"label_id\"])]\n","    })\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Or7MpNbkI-w3"},"outputs":[{"data":{"text/html":["Finishing last run (ID:3ddqjk71) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 16740... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","</div><div class=\"wandb-col\">\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">gallant-universe-22</strong>: <a href=\"https://wandb.ai/bex_team/baseline_vgg19/runs/3ddqjk71\" target=\"_blank\">https://wandb.ai/bex_team/baseline_vgg19/runs/3ddqjk71</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220216_161852-3ddqjk71\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:3ddqjk71). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/baseline_vgg19/runs/37c6qvrd\" target=\"_blank\">blooming-star-23</a></strong> to <a href=\"https://wandb.ai/bex_team/baseline_vgg19\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyError","evalue":"'0'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\g3\\lib\\site-packages\\wandb\\data_types.py\u001b[0m in \u001b[0;36madd_computed_columns\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mndx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mnew_row_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_row_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_row_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(ndx, row)\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: '0'"]}],"source":["%%time\n","\n","# Initialize a new W&B run\n","run = wandb.init(project=\"baseline_vgg19\",\n","                 entity=\"bex_team\",\n","                 group=\"Pictures\",\n","                 job_type=\"Baseline\")\n","\n","# Intialize a W&B Artifacts\n","ds = wandb.Artifact(configs[\"dataset\"], \"dataset\")\n","\n","# Initialize an empty table\n","train_table = wandb.Table(columns=[], data=[])\n","# Add training data\n","train_table.add_column('image', X_train[:log_train_samples])\n","# Add training label_id\n","train_table.add_column('label_id', y_train[:log_train_samples])\n","# Add training class names\n","train_table.add_computed_columns(lambda ndx, row:{\n","    \"images\": wandb.Image(row[\"image\"]),\n","    \"class_names\": configs['class_names'][str(row[\"label_id\"])]\n","    })\n","\n","# Add the table to the Artifact\n","# ds['train_data'] = train_table\n","\n","# # Let's do the same for the validation data\n","# valid_table = wandb.Table(columns=[], data=[])\n","# valid_table.add_column('image', X_val)\n","# valid_table.add_column('label_id', y_val)\n","# valid_table.add_computed_columns(lambda ndx, row:{\n","#     \"images\": wandb.Image(row[\"image\"]),\n","#     \"class_name\": configs['class_names'][str(row[\"label_id\"])]\n","#     })\n","# ds['valid_data'] = valid_table\n","\n","# Save the dataset as an Artifact\n","ds.save()\n","\n","# Finish the run\n","wandb.finish()"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"wmjJlRYqI-w6"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n","Model: \"Baseline_VGG19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n","                                                                 \n"," vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 20,024,897\n","Trainable params: 513\n","Non-trainable params: 20,024,384\n","_________________________________________________________________\n"]}],"source":["def get_model(input_shape: tuple=(32, 32, 3),\n","              output_activation: str='sigmoid'):\n","\n","    inputs = layers.Input(input_shape)\n","\n","    base_model = vgg19.VGG19(weights=configs['pretrain_weights'], include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    configs['architecture'] = f\"{base_model._name.upper()} global_average_pooling2d\"\n","\n","    inputs = layers.Input(shape=(X_train[0].shape[0], X_train[0].shape[1], 3))\n","    x = vgg19.preprocess_input(inputs)\n","    x = base_model(x)\n","    x = layers.GlobalAveragePooling2D()(x)\n","    # x = Flatten()(x)\n","    outputs = layers.Dense(1, activation=output_activation)(x)\n","\n","    return models.Model(inputs, outputs, name=f'Baseline_{base_model._name.upper()}')\n","\n","tf.keras.backend.clear_session()\n","model = get_model()\n","model.summary()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["checkpoint_filepath = (Path(os.getcwd()) /'model_checkpoint/model_checkpoint')\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"XUld9o-zI-w6"},"outputs":[],"source":["earlystopper = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss', patience=configs['earlystopping_patience'], verbose=0, mode='auto',\n","    restore_best_weights=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"FCd5Ao88I-w6"},"source":["You can use `wandb.log` to log any useful metric/parameter that's not logged by `WandbCallback`. Here we are using a learning rate scheduler to exponentially decay the learning rate after 10 epochs. Notice the use of `wandb.log` to capture the learning rate and `commit=False` in particular.\n","\n","You can learn more about `wandb.log` [here](https://docs.wandb.ai/guides/track/log).\n","\n","def lr_scheduler(epoch, lr):\n","    # log the current learning rate onto W&B\n","    if wandb.run is None:\n","        raise wandb.Error(\"You must call wandb.init() before WandbCallback()\")\n","\n","    wandb.log({'learning_rate': lr}, commit=False)\n","    \n","    if epoch < 7:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-configs['lr_decay_rate'])\n","\n","lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"kORq8cZJI-w7"},"outputs":[],"source":["def train(config: dict,\n","          callbacks: list,\n","          verbose: int=0):\n","    \"\"\"\n","    Utility function to train the model.\n","\n","    Arguments:\n","        config (dict): Dictionary of hyperparameters.\n","        callbacks (list): List of callbacks passed to `model.fit`.\n","        verbose (int): 0 for silent and 1 for progress bar.\n","    \"\"\"\n","\n","    # Initalize model\n","    tf.keras.backend.clear_session()\n","    model = get_model(input_shape=(config.image_width, config.image_height, config.image_channels))\n","    config['model_name'] = model.name # set\n","\n","\n","    # Compile the model\n","    opt = tf.keras.optimizers.Adam(learning_rate=config.init_learning_rate)\n","    model.compile(optimizer=opt,\n","                  loss=config.loss_fn,\n","                  metrics=config.metrics)\n","# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)\n","    # Train the model\n","    # _ = model.fit(np.array(X_train), np.array(y_train),\n","    #               epochs=config.epochs,\n","    #               validation_data=(np.array(X_val),np.array(y_val)),\n","    #               callbacks=callbacks,\n","    #               batch_size=config.batch_size,\n","    #               verbose=verbose)\n","    _ = model.fit(trainloader,\n","                  epochs=config.epochs,\n","                  validation_data=validloader,\n","                  callbacks=callbacks,\n","                #   batch_size=config.batch_size,\n","                  verbose=verbose)\n","    return model"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"dbrdw5KoI-w7"},"outputs":[{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/test_wandb/runs/24sapwbh\" target=\"_blank\">stellar-wildflower-3</a></strong> to <a href=\"https://wandb.ai/bex_team/test_wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Error initializing ValidationDataLogger in WandbCallback. Skipping logging validation data. Error: \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","4/4 - 44s - loss: 3.1630 - accuracy: 0.4000 - val_loss: 1.4555 - val_accuracy: 0.5476 - 44s/epoch - 11s/step\n","Epoch 2/5\n","4/4 - 40s - loss: 1.3270 - accuracy: 0.5440 - val_loss: 0.5949 - val_accuracy: 0.7381 - 40s/epoch - 10s/step\n","Epoch 3/5\n","4/4 - 42s - loss: 0.6289 - accuracy: 0.7120 - val_loss: 0.7999 - val_accuracy: 0.6667 - 42s/epoch - 11s/step\n","Epoch 4/5\n","4/4 - 44s - loss: 0.7917 - accuracy: 0.7120 - val_loss: 1.0136 - val_accuracy: 0.6667 - 44s/epoch - 11s/step\n","Epoch 5/5\n","4/4 - 41s - loss: 0.8755 - accuracy: 0.6880 - val_loss: 0.8912 - val_accuracy: 0.6905 - 41s/epoch - 10s/step\n","2/2 [==============================] - 10s 2s/step - loss: 0.8912 - accuracy: 0.6905\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 12296... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄██▇</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>evaluate/accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▃▁▁▂</td></tr><tr><td>val_accuracy</td><td>▁█▅▅▆</td></tr><tr><td>val_loss</td><td>█▁▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.688</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.59492</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>evaluate/accuracy</td><td>0.69048</td></tr><tr><td>loss</td><td>0.87552</td></tr><tr><td>val_accuracy</td><td>0.69048</td></tr><tr><td>val_loss</td><td>0.89117</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">stellar-wildflower-3</strong>: <a href=\"https://wandb.ai/bex_team/test_wandb/runs/24sapwbh\" target=\"_blank\">https://wandb.ai/bex_team/test_wandb/runs/24sapwbh</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220216_163637-24sapwbh\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize the W&B run\n","run = wandb.init(project='test_wandb', config=configs, job_type='Baseline')\n","config = wandb.config\n","\n","# Define WandbCallback for experiment tracking\n","wandb_callback = WandbCallback(monitor='val_loss',\n","                               log_weights=True,\n","                               log_evaluation=True,\n","                               validation_steps=5,\n","                               )\n","# WandbCallback(data_type='image', training_data=(np.array(X_val),np.array(y_val)), labels=CLASSES, save_model=True, save_graph=True)\n","# callbacks\n","callbacks = [earlystopper, wandb_callback]#lr_callback\n","\n","# Train\n","model = train(config, callbacks=callbacks, verbose=2)\n","\n","# Evaluate the trained model\n","loss, acc = model.evaluate(validloader)\n","wandb.log({'evaluate/accuracy': acc})\n","\n","# Close the W&B run.\n","wandb.finish()"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"PJU_xbWCI-w8"},"outputs":[],"source":["#@title\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()\n","\n","def create_gradcam(image, model, last_conv_layer_name, pred_index=None):\n","    # Preprocess the image array\n","    image, _ = preprocess(tf.expand_dims(image, axis=0), 0)\n","    # Get GradCAM\n","    heatmap = make_gradcam_heatmap(image, model, last_conv_layer_name, pred_index)\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = cm.get_cmap(\"jet\")\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","    jet_heatmap = tf.image.resize(jet_heatmap, size=(28,28))\n","\n","    # Overlay\n","    superimposed_img = jet_heatmap * 0.4 + tf.squeeze(image, axis=0)\n","    superimposed_img = tf.clip_by_value(superimposed_img, 0.0, 1.0)\n","\n","    return superimposed_img"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"_yUye2ChI-w8"},"outputs":[],"source":["last_conv_layer_name = 'block4_conv3'"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"25T7JVt4I-w8"},"outputs":[],"source":["def validation_processor(ndx, row):\n","    return {\n","        \"input:image\": wandb.Image(row[\"input\"]),\n","        \"target:class\": class_table.index_ref(row[\"target\"])\n","    }\n","\n","def prediction_processor(ndx, row):\n","    # Get the validation image\n","    valid_image = np.array(row[\"val_row\"].get_row()[\"input:image\"].image)\n","\n","    return {\n","        \"output:class\": class_table.index_ref(np.argmax(row[\"output\"])),\n","        \"gradcam\": wandb.Image(create_gradcam(valid_image, model, last_conv_layer_name)),\n","        \"output:logits\": {class_name: value for (class_name, value) in zip(list(config.class_names.values()), row[\"output\"].tolist())}\n","    }"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"PiJJ9HjCI-w8"},"outputs":[{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/medmnist-bloodmnist/runs/bd44lepf\" target=\"_blank\">lemon-leaf-1</a></strong> to <a href=\"https://wandb.ai/bex_team/medmnist-bloodmnist\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Error initializing ValidationDataLogger in WandbCallback. Skipping logging validation data. Error: \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","4/4 - 43s - loss: 1.2269 - accuracy: 0.4560 - val_loss: 1.3816 - val_accuracy: 0.5238 - 43s/epoch - 11s/step\n","Epoch 2/5\n","4/4 - 43s - loss: 1.0762 - accuracy: 0.6320 - val_loss: 1.1772 - val_accuracy: 0.5476 - 43s/epoch - 11s/step\n","Epoch 3/5\n","4/4 - 41s - loss: 0.9123 - accuracy: 0.6000 - val_loss: 0.9648 - val_accuracy: 0.4762 - 41s/epoch - 10s/step\n","Epoch 4/5\n","4/4 - 40s - loss: 0.7945 - accuracy: 0.6320 - val_loss: 0.8947 - val_accuracy: 0.5476 - 40s/epoch - 10s/step\n","Epoch 5/5\n","4/4 - 41s - loss: 0.6999 - accuracy: 0.6720 - val_loss: 0.8413 - val_accuracy: 0.5952 - 41s/epoch - 10s/step\n","2/2 [==============================] - 13s 3s/step - loss: 0.8413 - accuracy: 0.5952\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 3876... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▆▇█</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>evaluate/accuracy</td><td>▁</td></tr><tr><td>loss</td><td>█▆▄▂▁</td></tr><tr><td>val_accuracy</td><td>▄▅▁▅█</td></tr><tr><td>val_loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.672</td></tr><tr><td>best_epoch</td><td>4</td></tr><tr><td>best_val_loss</td><td>0.8413</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>evaluate/accuracy</td><td>0.59524</td></tr><tr><td>loss</td><td>0.69994</td></tr><tr><td>val_accuracy</td><td>0.59524</td></tr><tr><td>val_loss</td><td>0.8413</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">lemon-leaf-1</strong>: <a href=\"https://wandb.ai/bex_team/medmnist-bloodmnist/runs/bd44lepf\" target=\"_blank\">https://wandb.ai/bex_team/medmnist-bloodmnist/runs/bd44lepf</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220216_164301-bd44lepf\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize the W&B run\n","run = wandb.init(project='baseline_vgg19', config=configs, job_type='train')\n","config = wandb.config\n","\n","# Get validation table\n","data_art = run.use_artifact(f'{configs[\"dataset\"]}:latest', type='dataset')\n","valid_table = data_art.get(\"valid_data\")\n","\n","# Create a class table\n","class_table = wandb.Table(columns=[], data=[])\n","class_table.add_column(\"class_name\", list(config.class_names.values()))\n","\n","# Define WandbCallback for experiment tracking\n","wandb_callback = WandbCallback(\n","                    log_evaluation=True,\n","                    validation_row_processor=lambda ndx, row: validation_processor(ndx, row),\n","                    prediction_row_processor=lambda ndx, row: prediction_processor(ndx, row),\n","                    validation_steps=4,\n","                    save_model=False\n","                )\n","\n","# callbacks\n","callbacks = [earlystopper, wandb_callback]#lr_callback\n","\n","# Train\n","model = train(config, callbacks=callbacks, verbose=2)\n","\n","# Evaluate the trained model\n","loss, acc = model.evaluate(validloader)\n","wandb.log({'evaluate/accuracy': acc})\n","\n","# Close the W&B run.\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"Copy of Keras_pipeline_with_Weights_and_Biases.ipynb","provenance":[{"file_id":"https://github.com/wandb/examples/blob/master/colabs/keras/Keras_pipeline_with_Weights_and_Biases.ipynb","timestamp":1645008414025}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
