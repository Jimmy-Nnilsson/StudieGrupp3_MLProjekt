{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6734,"status":"ok","timestamp":1646231492743,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"EAGV1HZ2X6-n","outputId":"860dcb91-23fd-4e65-c952-be28caf2f3b3"},"outputs":[],"source":["# Setup if running in colab\n","RunningInCOLAB = 'google.colab' in str(get_ipython())\n","if RunningInCOLAB:\n","  try:\n","    if runonce:\n","      print(\"Already ran\")\n","  \n","  except:\n","    runonce = True\n","    !pip install wandb\n","    !git clone https://github.com/Jimmy-Nnilsson/StudieGrupp3_MLProjekt.git\n","    \n","    import wandb\n","    wandb.login()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3761,"status":"ok","timestamp":1646231496494,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"uuJ29hLgFeGb"},"outputs":[],"source":["import tqdm\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.image import load_img, img_to_array\n","\n","import os\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1646231496496,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"SEjzTuEvFeGc","outputId":"8a256255-6b26-49f5-e760-642238eae8eb"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.login()"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1646231496497,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"rl9dXKzWX6-8"},"outputs":[],"source":["# Get base project directory\n","if not RunningInCOLAB:\n","#   project_path = Path(os.getcwd()).parent.parent\n","\n","  for i, p in enumerate(Path(os.getcwd()).parts):\n","    if p == \"StudieGrupp3_MLProjekt\":\n","        break\n","    pathparts = list(Path(os.getcwd()).parts[0:i+2])\n","    project_path = Path(pathparts[0],\"\\\\\\\\\".join(pathparts[1:]))\n","else:\n","  project_path = Path('/content/StudieGrupp3_MLProjekt/')\n","datapath = (project_path /'data/processed/')\n","\n","CLASSES = {0 : 'yes', 1 : 'no'}\n","# Loops through pathlist and reads and resizes images\n","def read_image(pathlist : list, size : int)-> list:\n","    data = []\n","    for path in pathlist:\n","        image=load_img(path, color_mode='rgb', target_size=(size, size))\n","        # image=load_img(path, color_mode='rgb', target_size=(size, size))\n","        image=img_to_array(image)\n","        # image=image/255.0\n","        data.append(image)\n","    data = np.asarray(data, dtype=np.uint8)\n","    return data\n","\n","# Makes input and label data from folder locations.\n","# Loops through location \"subfolder/CLASSES\"\n","def get_sets(subfolder : str, CLASSES : dict, size : int):\n","    folder_paths = []\n","    folder_labels = []\n","    labels = []\n","    for k,v in CLASSES.items():\n","        # input datapath generation\n","        folder_paths += list((datapath / f\"2_split_{v}/{subfolder}\").rglob(\"*\"))\n","    # Label data generation\n","    folder_labels = [0 if x.stem.split('_')[1] == 'yes' else 1 for x in folder_paths]\n","    folder_labels = np.asarray(folder_labels, dtype=np.uint8)\n","    # Extract images from datapaths\n","    img_list = read_image(folder_paths, size)\n","\n","    return img_list, folder_labels\n","\n","def get_training_set(CLASSES : dict, size : int):\n","    folder_paths = []\n","    folder_labels = []\n","    labels = []\n","    for k,v in CLASSES.items():\n","        # input datapath generation\n","        folder_paths += list((datapath / f\"3_aug_{v}_train/\").rglob(\"*\"))\n","        # folder_paths += list((datapath / f\"3_augmentation_train/3_aug_geo_{v}_train/\").rglob(\"*\"))\n","        # folder_paths += list((datapath / f\"3_augmentation_train/3_aug_pix_{v}_train/\").rglob(\"*\"))\n","        # print(folder_paths)\n","    # Label data generation\n","    folder_labels = [0 if x.stem.split('_')[1] == 'yes' else 1 for x in folder_paths]\n","    # Extract images from datapaths\n","    img_list = read_image(folder_paths, size)\n","\n","    return img_list, folder_labels"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5311,"status":"ok","timestamp":1646231501795,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"44luz-esX6_F"},"outputs":[],"source":["# Dataset inspect\n","# Read images to variables\n","size = 224\n","X_aug_train, y_aug_train = get_training_set(CLASSES, size)\n","# X_train, y_train = get_sets('train', CLASSES, size)\n","X_val, y_val = get_sets('val', CLASSES, size)\n","# X_test, y_test = get_sets('test', CLASSES, size)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1143,"status":"ok","timestamp":1646231502932,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"tKUkFh65X6_I"},"outputs":[],"source":["# Mind model processing\n","# Finetune not complete\n","configs = dict(\n","    project_name = \"s4\", #Project Name\n","    mode = 'run', #{'offline', 'run', 'disabled', 'dryrun', 'online'} # WandB run status\n","    job_type = \"\", #Run type for WandB\n","    group = \"\", # Group in WandB\n","    sub_group = \"_95model\",\n","\n","    class_names = CLASSES, # Classes for training\n","    training_set = (keras.applications.vgg19.preprocess_input(X_aug_train), y_aug_train),\n","\n","    # image_width = X_train[0].shape[0], # Picture width for model input\n","    # image_height = X_train[0].shape[1], # Picture height for model input\n","    # image_channels = X_train[0].shape[2], # Picture channels for model input\n","\n","    pretrain_weights = 'imagenet', # pretrained weights for basemodel if any\n","    batch_size = 4, # Batchsize for training\n","    init_learning_rate = 0.001, # Initial training rate if no callback is used\n","    lr_decay_rate = 0.1, #decayrate of training rate\n","    epochs = 50, # Epochs to train\n","    optimizer = 'adam', # The optimizer used by the ml model\n","    loss_fn = 'binary_crossentropy', # Loss function\n","    metrics = ['accuracy'], # Metrics\n","    earlystopping_patience = 5, # For the early stopping callback\n","\n","    dataset = \"Brain_MRI_Images_for_Brain_Tumor_Detection\",\n","    fine_tune_learning_rate = 1e-5, # learningrate Used during fine tuning\n","    fine_tune_epochs = 10, # Epochs ran at finetuning\n","\n","    architecture = \"\",# To be defined f\"{base_model._name.upper()} global_average_pooling2d\",\n","    model_name = '' # set after model is defined # Name of the ml Model\n","\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646231502933,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"lwTNGa2GX6_L"},"outputs":[],"source":["sweep_config = {\n","    'method': \"random\",\n","    'metric': {\n","        'name': 'accuracy',\n","        'goal': 'maximize',\n","    },\n","    'parameters': {\n","        \"optimizer\": {\n","            \"values\": ['adam', 'sgd', 'rmsprop']\n","        },\n","        \"nodes\": {\n","            \"values\": [128, 256, 512]\n","        },\n","        \"epochs\": {\n","            \"values\": [1,2,3,5]\n","        },\n","        \"learning_rate\": {\n","            \"distribution\": \"uniform\",\n","            \"min\": 0.0001,\n","            \"max\": 0.1\n","        },\n","        \"batch_size\": {\n","            \"distribution\": \"q_log_uniform\",\n","            \"q\": 1,\n","            \"min\": 32,\n","            \"max\": 128\n","        },\n","    },\n","}"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646231502935,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"xno5YgDxFeGg"},"outputs":[],"source":["sweep_config = {\n","  'method': 'random', \n","  'metric': {\n","      'name': 'val_loss',\n","      'goal': 'minimize'\n","  },\n","  'early_terminate':{\n","      'type': 'hyperband',\n","      'min_iter': 5\n","  },\n","  'parameters': {\n","        \"optimizer\": {\n","            \"values\": ['adam', 'sgd', 'rmsprop']\n","        },\n","      'batch_size': {\n","          'values': [4, 8, 16, 32, 64]\n","      },\n","      'learning_rate':{\n","          'values': [0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]\n","      }\n","  }\n","}"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1646231502936,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"zR3Uqm2TX6_P"},"outputs":[],"source":["def Model(path):\n","\n","    model = tf.keras.models.load_model(path)\n","    model.load_weights(path)\n","    configs['group'] = f'{model._name}{configs[\"sub_group\"]}'\n","    configs['architecture'] = model._name\n","    return model\n","\n","    \n","def train_step(x, y, model, optimizer, loss_fn, train_acc_metric):\n","    with tf.GradientTape() as tape:\n","        logits = model(x, training=True)\n","        loss_value = loss_fn(y, logits)\n","\n","    grads = tape.gradient(loss_value, model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","    train_acc_metric.update_state(y, logits)\n","\n","    return loss_value\n","\n","    \n","def test_step(x, y, model, loss_fn, val_acc_metric):\n","    val_logits = model(x, training=False)\n","    loss_value = loss_fn(y, val_logits)\n","    val_acc_metric.update_state(y, val_logits)\n","\n","    return loss_value"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1646231503422,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"kX8NiGBwFeGf"},"outputs":[],"source":["def train(train_dataset,\n","          val_dataset, \n","          model,\n","          optimizer,\n","          loss_fn,\n","          train_acc_metric,\n","          val_acc_metric,\n","          epochs=10, \n","          log_step=200, \n","          val_log_step=50):\n","  \n","    for epoch in range(epochs):\n","        print(\"\\nStart of epoch %d\" % (epoch,))\n","\n","        train_loss = []\n","        val_loss = []\n","\n","        # Iterate over the batches of the dataset\n","        for step, (x_batch_train, y_batch_train) in tqdm.tqdm(enumerate(train_dataset), total=len(train_dataset)):\n","            loss_value = train_step(x_batch_train, y_batch_train, \n","                                    model, optimizer, \n","                                    loss_fn, train_acc_metric)\n","            train_loss.append(float(loss_value))\n","\n","        # Run a validation loop at the end of each epoch\n","        for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n","            val_loss_value = test_step(x_batch_val, y_batch_val, \n","                                       model, loss_fn, \n","                                       val_acc_metric)\n","            val_loss.append(float(val_loss_value))\n","\n","        # Display metrics at the end of each epoch\n","        train_acc = train_acc_metric.result()\n","        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n","\n","        val_acc = val_acc_metric.result()\n","        print(\"Validation acc: %.4f\" % (float(val_acc),))\n","\n","        # Reset metrics at the end of each epoch\n","        train_acc_metric.reset_states()\n","        val_acc_metric.reset_states()\n","\n","        # 3️⃣ log metrics using wandb.log\n","        wandb.log({'epochs': epoch,\n","                   'loss': np.mean(train_loss),\n","                   'acc': float(train_acc), \n","                   'val_loss': np.mean(val_loss),\n","                   'val_acc':float(val_acc)})"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646231503423,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"VZFhIcJkFeGg"},"outputs":[],"source":["def sweep_train(config_defaults=None):\n","    # Set default values\n","    config_defaults = {\n","        \"batch_size\": 64,\n","        \"learning_rate\": 0.01\n","    }\n","    # Initialize wandb with a sample project name\n","    wandb.init(config=config_defaults)  # this gets over-written in the Sweep\n","\n","    # Specify the other hyperparameters to the configuration, if any\n","    wandb.config.epochs = 2\n","    wandb.config.log_step = 20\n","    wandb.config.val_log_step = 50\n","    wandb.config.architecture_name = configs['model_name']\n","    wandb.config.dataset_name = configs['dataset']\n","\n","    # build input pipeline using tf.data\n","    train_dataset = tf.data.Dataset.from_tensor_slices(configs['training_set'])\n","    train_dataset = (train_dataset.shuffle(buffer_size=512)\n","                                  .batch(wandb.config.batch_size)\n","                                  .prefetch(buffer_size=tf.data.AUTOTUNE))\n","\n","    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","    val_dataset = (val_dataset.batch(wandb.config.batch_size)\n","                              .prefetch(buffer_size=tf.data.AUTOTUNE))\n","\n","    # initialize model\n","    model = Model((project_path / \"models/first_golden_model.h5\"))\n","\n","    # Instantiate an optimizer to train the model.\n","    if wandb.config.optimizer == \"sgd\":\n","        optimizer = keras.optimizers.SGD(learning_rate=wandb.config.learning_rate)\n","    elif wandb.config.optimizer == \"rmsprop\":\n","        optimizer = keras.optimizers.RMSprop(learning_rate=wandb.config.learning_rate)\n","    elif wandb.config.optimizer == \"adam\":\n","        optimizer = keras.optimizers.Adam(learning_rate=wandb.config.learning_rate)\n","\n","    # Instantiate a loss function.\n","    loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","    # Prepare the metrics.\n","    train_acc_metric = keras.metrics.BinaryAccuracy()\n","    val_acc_metric = keras.metrics.BinaryAccuracy()\n","\n","    train(train_dataset,\n","          val_dataset, \n","          model,\n","          optimizer,\n","          loss_fn,\n","          train_acc_metric,\n","          val_acc_metric,\n","          epochs=wandb.config.epochs, \n","          log_step=wandb.config.log_step, \n","          val_log_step=wandb.config.val_log_step)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1716,"status":"ok","timestamp":1646231505134,"user":{"displayName":"Jimmy Nilsson","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16604156050067165706"},"user_tz":-60},"id":"m-GPPyrqFeGh","outputId":"f8271790-9c9e-4cf2-dd89-39df75c885c1"},"outputs":[],"source":["# sweep_id = wandb.sweep(sweep_config, project=configs['project_name'])\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"sIETIYF0FeGh","outputId":"89e92b98-078a-4e7b-ffc4-c5b1cd368c1f"},"outputs":[],"source":["# wandb.agent(sweep_id, function=sweep_train, count=10)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ZOK18wE6X6_e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Create sweep with ID: 8i04wlny\n","Sweep URL: https://wandb.ai/bex_team/s4/sweeps/8i04wlny\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bzbm561d with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","C:\\Users\\big_j\\anaconda3\\envs\\ecpython\\lib\\site-packages\\IPython\\html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n","  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/bzbm561d\" target=\"_blank\">ethereal-sweep-2</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:48<00:00,  1.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.6377\n","Validation acc: 0.9048\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:42<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.6709\n","Validation acc: 0.8810\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 988... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>█▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.6709</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.68004</td></tr><tr><td>val_acc</td><td>0.88095</td></tr><tr><td>val_loss</td><td>0.59339</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-2</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/bzbm561d\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/bzbm561d</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_153650-bzbm561d\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xycbkv3z with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/xycbkv3z\" target=\"_blank\">misty-sweep-3</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:04<00:00,  7.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9055\n","Validation acc: 0.7727\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:05<00:00,  7.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9210\n","Validation acc: 0.7045\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 8588... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>█▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.921</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.59154</td></tr><tr><td>val_acc</td><td>0.70455</td></tr><tr><td>val_loss</td><td>0.70009</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">misty-sweep-3</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/xycbkv3z\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/xycbkv3z</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_153845-xycbkv3z\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a8ffzjgg with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/a8ffzjgg\" target=\"_blank\">dashing-sweep-5</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:04<00:00,  7.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8810\n","Validation acc: 0.8864\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:05<00:00,  7.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8830\n","Validation acc: 0.8864\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 8456... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.883</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.60779</td></tr><tr><td>val_acc</td><td>0.88636</td></tr><tr><td>val_loss</td><td>0.57436</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">dashing-sweep-5</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/a8ffzjgg\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/a8ffzjgg</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_154126-a8ffzjgg\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lrxv8ndc with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/lrxv8ndc\" target=\"_blank\">ancient-sweep-7</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:46<00:00,  1.46s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.7988\n","Validation acc: 0.8333\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:40<00:00,  1.26s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8779\n","Validation acc: 0.8571\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 13880... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁█</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.87793</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.61073</td></tr><tr><td>val_acc</td><td>0.85714</td></tr><tr><td>val_loss</td><td>0.61297</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">ancient-sweep-7</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/lrxv8ndc\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/lrxv8ndc</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_154409-lrxv8ndc\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vh3hb8dl with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/vh3hb8dl\" target=\"_blank\">feasible-sweep-8</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [00:43<00:00,  2.84it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9270\n","Validation acc: 0.7583\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [00:41<00:00,  2.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9245\n","Validation acc: 0.7792\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 12836... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>█▁</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.9245</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.58879</td></tr><tr><td>val_acc</td><td>0.77917</td></tr><tr><td>val_loss</td><td>0.63488</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">feasible-sweep-8</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/vh3hb8dl\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/vh3hb8dl</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_154558-vh3hb8dl\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9vke1y47 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/9vke1y47\" target=\"_blank\">grateful-sweep-9</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [00:41<00:00,  2.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8815\n","Validation acc: 0.8708\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [00:42<00:00,  2.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8830\n","Validation acc: 0.8708\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 10000... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.883</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.60773</td></tr><tr><td>val_acc</td><td>0.87083</td></tr><tr><td>val_loss</td><td>0.56262</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">grateful-sweep-9</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/9vke1y47\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/9vke1y47</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_154749-9vke1y47\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0y1q72d0 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/0y1q72d0\" target=\"_blank\">glowing-sweep-11</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 250/250 [00:53<00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.6320\n","Validation acc: 0.5000\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 250/250 [00:52<00:00,  4.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.6320\n","Validation acc: 0.5000\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 4308... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.632</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.69315</td></tr><tr><td>val_acc</td><td>0.5</td></tr><tr><td>val_loss</td><td>0.69315</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">glowing-sweep-11</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/0y1q72d0\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/0y1q72d0</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_154938-0y1q72d0\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vgv0ae63 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/vgv0ae63\" target=\"_blank\">serene-sweep-12</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:03<00:00,  7.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9275\n","Validation acc: 0.8409\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:02<00:00,  7.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9490\n","Validation acc: 0.7727\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 2676... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>█▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.949</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.57888</td></tr><tr><td>val_acc</td><td>0.77273</td></tr><tr><td>val_loss</td><td>0.64906</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">serene-sweep-12</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/vgv0ae63\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/vgv0ae63</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_155149-vgv0ae63\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: unnqvyvd with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/unnqvyvd\" target=\"_blank\">faithful-sweep-14</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [00:43<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8915\n","Validation acc: 0.8417\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [00:41<00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9085\n","Validation acc: 0.8208\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 4464... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>█▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.9085</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.59423</td></tr><tr><td>val_acc</td><td>0.82083</td></tr><tr><td>val_loss</td><td>0.60906</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">faithful-sweep-14</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/unnqvyvd\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/unnqvyvd</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_155421-unnqvyvd\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mfpoe526 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/mfpoe526\" target=\"_blank\">proud-sweep-15</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:42<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8730\n","Validation acc: 0.8571\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:45<00:00,  1.42s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8916\n","Validation acc: 0.8571\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 872... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>▁█</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.8916</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.60151</td></tr><tr><td>val_acc</td><td>0.85714</td></tr><tr><td>val_loss</td><td>0.6109</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">proud-sweep-15</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/mfpoe526\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/mfpoe526</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_155611-mfpoe526\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8vpl1ypw with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/8vpl1ypw\" target=\"_blank\">helpful-sweep-17</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:42<00:00,  1.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8824\n","Validation acc: 0.8687\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 63/63 [00:39<00:00,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8805\n","Validation acc: 0.8687\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 1500... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>█▁</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>▁█</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.88046</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.60771</td></tr><tr><td>val_acc</td><td>0.86875</td></tr><tr><td>val_loss</td><td>0.51994</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">helpful-sweep-17</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/8vpl1ypw\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/8vpl1ypw</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_155758-8vpl1ypw\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 45qgkr43 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/45qgkr43\" target=\"_blank\">morning-sweep-18</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8994\n","Validation acc: 0.7381\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 32/32 [00:45<00:00,  1.42s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.9321\n","Validation acc: 0.7381\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 12704... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.93213</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.58261</td></tr><tr><td>val_acc</td><td>0.7381</td></tr><tr><td>val_loss</td><td>0.70438</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">morning-sweep-18</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/45qgkr43\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/45qgkr43</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_155949-45qgkr43\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ho490866 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n","\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/bex_team/s4/runs/ho490866\" target=\"_blank\">good-sweep-19</a></strong> to <a href=\"https://wandb.ai/bex_team/s4\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","Sweep page: <a href=\"https://wandb.ai/bex_team/s4/sweeps/85dzi8dy\" target=\"_blank\">https://wandb.ai/bex_team/s4/sweeps/85dzi8dy</a><br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 250/250 [00:54<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8840\n","Validation acc: 0.8750\n","\n","Start of epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 250/250 [00:53<00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training acc over epoch: 0.8990\n","Validation acc: 0.8750\n"]},{"data":{"text/html":["<br/>Waiting for W&B process to finish, PID 10744... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁█</td></tr><tr><td>epochs</td><td>▁█</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.899</td></tr><tr><td>epochs</td><td>1</td></tr><tr><td>loss</td><td>0.60217</td></tr><tr><td>val_acc</td><td>0.875</td></tr><tr><td>val_loss</td><td>0.57165</td></tr></table>\n","</div></div>\n","Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">good-sweep-19</strong>: <a href=\"https://wandb.ai/bex_team/s4/runs/ho490866\" target=\"_blank\">https://wandb.ai/bex_team/s4/runs/ho490866</a><br/>\n","Find logs at: <code>.\\wandb\\run-20220302_160140-ho490866\\logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["sweep_id = wandb.sweep(sweep_config, project=configs['project_name'])\n","sweep_id = \"85dzi8dy\"\n","\n","\n","wandb.agent(sweep_id, function=sweep_train, count=10)\n","\n","wandb.agent(\n","    sweep_id, function=sweep_train, entity=\"bex_team\", project=configs['project_name'], count=3\n",")"]},{"cell_type":"markdown","metadata":{"id":"XMK449pHGHBB"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"s4_prvt_Hyperparameter_Optimization_in_TensorFlow_using_W&B_Sweeps.ipynb","provenance":[{"file_id":"https://github.com/wandb/examples/blob/master/colabs/tensorflow/Hyperparameter_Optimization_in_TensorFlow_using_W%26B_Sweeps.ipynb","timestamp":1645846389613}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
